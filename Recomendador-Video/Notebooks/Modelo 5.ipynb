{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 5\n",
    "\n",
    "Este módulo está associado a fechar o modelo que será utilizado no Deploy. Para isto, utilizaremos os três modelos finais considerados no Módulo 4  \n",
    "\n",
    "\n",
    "É importante ressaltar que foram revistos 0 e 1 aplicados a coluna 'y' para que tenha menos carga aleatória. Além disso, foi preenchido manualmente todas as informações de acordo com o título.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('raw_data_with_label_rev1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento dos dados\n",
    "\n",
    "Nesta etapa vamos retirar linhas repetidas a onde um mesmo video aparece para duas palavras-chaves (ex: Machine Learning e Kaggle).\n",
    "\n",
    "Além disso, vamos verificar os valores ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deletando as linhas duplicadas\n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          0\n",
       "y              0\n",
       "upload_date    2\n",
       "view_count     2\n",
       "query          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando a quantidade de nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deletando as linhas que estão com valores ausentes\n",
    "df.dropna(axis = 0, subset = ['upload_date', 'view_count', 'query'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo a variável date para datetime\n",
    "df['upload_date'] = pd.to_datetime(df['upload_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "Esta etapa está associada a criação de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Armazenando os dados com y preenchido\n",
    "df_preenchido = df.loc[ df['y'].notnull() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando um dataframe vazio para features com o mesmo índices do df_preenchido\n",
    "features = pd.DataFrame(index = df_preenchido.index)\n",
    "\n",
    "#Criando um dataframe exclusivo para y -> Variável Alvo\n",
    "y = df_preenchido['y'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criando uma feature de data desde da publicação**\n",
    "\n",
    "Como os modelos de Machine Learning não conseguem ler datas, devemos criar alguma forma para transformar estas datas em dados numéricos. Portanto, iremos fazer a diferença em relação a data de hoje (31/05/2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5 days\n",
       "1        5 days\n",
       "2        5 days\n",
       "3        5 days\n",
       "4        5 days\n",
       "         ...   \n",
       "1505   915 days\n",
       "1506   938 days\n",
       "1507   942 days\n",
       "1508   950 days\n",
       "1509   951 days\n",
       "Name: upload_date, Length: 1507, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime('2021/05/31')-df_preenchido['upload_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar vem com a palavras \"days\" e no formato timedelta64. Para contornarmos isto, utilizaremos um método do numpy chamado **timedelta64** em que passaremos como argumento a diferença de um dia, já que os dados estão associados a diferença diária. Isto permite que os valores sejam convertidos para float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         5.0\n",
       "1         5.0\n",
       "2         5.0\n",
       "3         5.0\n",
       "4         5.0\n",
       "        ...  \n",
       "1505    915.0\n",
       "1506    938.0\n",
       "1507    942.0\n",
       "1508    950.0\n",
       "1509    951.0\n",
       "Name: upload_date, Length: 1507, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.to_datetime('2021/05/31')-df_preenchido['upload_date'])/np.timedelta64(1, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando a feature de diferença diária\n",
    "features['tempo_desde_pub'] = (pd.to_datetime('2021/05/31')-df_preenchido['upload_date'])/np.timedelta64(1, 'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features - Views**\n",
    "Criando um conjunto de features para view.\n",
    "\n",
    "Iremos replicar o count_views e iremos calcular as views por dia, utilizando a feature tempo_desde_pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Armazenando as views\n",
    "features['views'] = df_preenchido['view_count']\n",
    "\n",
    "#Fazendo o cálculo de views por dia\n",
    "features['views_por_dia'] = features['views'] / features['tempo_desde_pub'] # Serve para avaliar a capacidade do video em promover views\n",
    "                                                                            # E desconsiderar o fator tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é uma séria temporal e os dados devem ser fatiados considerando a sequência temporal, a feature **tempo_desde_pub** vai trazer a mesma informação do que a variável **date**, ou seja, se fatiássemos em 01/01/2020, os valores antes desta data seriam menores e após seriam maiores, porque seguem a mesma sequência temporal.\n",
    "\n",
    "Diante disto, vamos deletar esta coluna do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deletando a variável tempo_desde_pub\n",
    "features.drop(['tempo_desde_pub'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "      <th>views_por_dia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.0</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   views  views_por_dia\n",
       "0    7.0            1.4\n",
       "1   27.0            5.4\n",
       "2    1.0            0.2\n",
       "3   20.0            4.0\n",
       "4    2.0            0.4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imprimindo as 5 primeiras linhas\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((515, 2), (992, 2), (515,), (992,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separando entre treino e teste\n",
    "mask_train = df_preenchido['upload_date'] < \"2020-04-03\" #Utilizado +- a metade do período temporal\n",
    "mask_val = df_preenchido['upload_date'] >= \"2020-04-03\"\n",
    "\n",
    "X_train, X_val = features[mask_train], features[mask_val]\n",
    "y_train, y_val = y[mask_train], y[mask_val]\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando o método\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Criando uma variável de títulos com os dados de treino e validação\n",
    "title_train = df_preenchido.loc[mask_train, 'title']\n",
    "title_val = df_preenchido.loc[mask_val, 'title']\n",
    "\n",
    "#Instanciando o objeto TfidfVectorizer\n",
    "title_vec = TfidfVectorizer(min_df = 2, ngram_range = (1,1))\n",
    "\n",
    "#Treinando e transformando os dados de treino referente ao título\n",
    "title_bow_train = title_vec.fit_transform(title_train)\n",
    "\n",
    "#Transformando os dados de validação com os parâmetros de treino\n",
    "title_bow_val = title_vec.transform(title_val)\n",
    "\n",
    "#o termo bow significa bag of words -> devido a matriz de palavras geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando o método hstack\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "#Aplicando o método hstack para juntar o X com as matrizes de bag of word\n",
    "X_train_wtitle = hstack([X_train, title_bow_train])\n",
    "X_val_wtitle = hstack([X_val, title_bow_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((515, 433), (992, 433))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imprimindo as dimensões\n",
    "X_train_wtitle.shape, X_val_wtitle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as bibliotecas\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', n_estimators=1000, n_jobs=6,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instanciando a RandomForest\n",
    "#Como os dados estão desbalanceados, vamos utilizar o argumento class_weight para dar mais peso a classe desbalanceada\n",
    "mdl = RandomForestClassifier(n_estimators=1000, random_state=0, min_samples_leaf = 1, class_weight=\"balanced\", n_jobs=6)\n",
    "mdl.fit(X_train_wtitle, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pegando as probabilidade\n",
    "p_rf = mdl.predict_proba(X_val_wtitle)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.581860377926327"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculando a metrica average_precision_score\n",
    "average_precision_score(y_val, p_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7551062780618204"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculando a ROC_AUC\n",
    "roc_auc_score(y_val, p_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LighGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "ROC_AUC = 0.7966338792141392\n",
      "AP = 0.6402330807008632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:739: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n"
     ]
    }
   ],
   "source": [
    "#Importando o modelo\n",
    "from lightgbm import LGBMClassifier\n",
    "#----------------------------------------------Criando a Bag of Words com os parâmetros tunados-------------------------------\n",
    "    \n",
    "#Instanciando o objeto TfidfVectorizer\n",
    "title_vec = TfidfVectorizer(min_df = 2, ngram_range = (1,1))\n",
    "\n",
    "#Treinando e transformando os dados de treino referente ao título\n",
    "title_bow_train = title_vec.fit_transform(title_train)\n",
    "\n",
    "#Transformando os dados de validação com os parâmetros de treino\n",
    "title_bow_val = title_vec.transform(title_val)\n",
    "    \n",
    " #----------------------------------------------Juntando o X com as bag of words -------------------------------------------\n",
    "    \n",
    "#Aplicando o método hstack para juntar o X com as matrizes de bag of word\n",
    "X_train_wtitle = hstack([X_train, title_bow_train])\n",
    "X_val_wtitle = hstack([X_val, title_bow_val])\n",
    "    \n",
    "#---------------------------------------------Tunando os parâmetros e aplicando-------------------------------------------\n",
    "\n",
    "#Instanciando o modelo\n",
    "mdl_lgm = LGBMClassifier(random_state = 42, \n",
    "                          class_weight=\"balanced\", \n",
    "                          n_jobs=6, \n",
    "                          learning_rate = 0.005607394468548006,\n",
    "                          num_leaves = 2 ** 7, #Para dar um sentido hipotético do tamanho da árvore, olhar comentário do Mario\n",
    "                          max_depth = 7,\n",
    "                          min_child_samples = 1,\n",
    "                          subsample = 0.6655993304551099,\n",
    "                          colsample_bytree = 0.9586294865021325,\n",
    "                          n_estimators = 523,\n",
    "                          bagging_freq = 1)\n",
    "\n",
    "#Treinando o modelo\n",
    "mdl_lgm.fit(X_train_wtitle, y_train)\n",
    "\n",
    "#Pegando as probabilidade\n",
    "p_lgm = mdl_lgm.predict_proba(X_val_wtitle)[:,1]\n",
    "\n",
    "#Calculando a ROC_AUC\n",
    "print(\"ROC_AUC = {}\".format(roc_auc_score(y_val, p_lgm)))\n",
    "    \n",
    "#Retorno da função custo \n",
    "print(\"AP = {}\".format(average_precision_score(y_val, p_lgm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressão Logística\n",
    "\n",
    "Como a diferença entre StandarScaler e MaxAbsScaler é muito pequeno. Seria melhor optar pelo MaxAbsScaler(), já que não é necessário filtrar as variáveis categórias, já que ele divide pelo maior número da coluna e qualquer divisão com 0 será 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as bibliotecas\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP = 0.5877241385790812\n",
      "ROC_AUC = 0.7701071864213231\n"
     ]
    }
   ],
   "source": [
    "#Instanciando o modelo\n",
    "lr_pipeline = make_pipeline(MaxAbsScaler(), LogisticRegression(n_jobs = 6, random_state = 42, class_weight=\"balanced\", C = 0.9638851701068524, solver = 'saga', penalty = 'l2'))\n",
    "    \n",
    "#Treinando o modelo\n",
    "lr_pipeline.fit(X_train_wtitle, y_train)\n",
    "    \n",
    "#Prevendo o modelo\n",
    "p_lr = lr_pipeline.predict_proba(X_val_wtitle)[:, 1]\n",
    "    \n",
    "#Calculando os scores\n",
    "print(\"AP = {}\".format(average_precision_score(y_val, p_lr) ))\n",
    "print(\"ROC_AUC = {}\".format(roc_auc_score(y_val, p_lr) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble\n",
    "\n",
    "Nesta etapa, vamos combinar os modelos para verificar se melhoram os scores das métricas escolhidas.\n",
    "\n",
    "Como os dados são relativamente simples e o conjunto é pequeno, não será aplicado modelos mais complexos de ensemble.\n",
    "\n",
    "Lembrando dos seguintes resultados:\n",
    "* Random Forest: Ap = 0.581860377926327 e ROC_AUC = 0.7551062780618204\n",
    "* LighGBM: Ap = 0.6402330807008632 e ROC_AUC = 0.7966338792141392\n",
    "* Regressão Logística: Ap = 0.5877241385790812 e ROC_AUC = 0.7701071864213231\n",
    "\n",
    "O próximo passo é aplicarmos uma média simples entre os resultados dos modelos para verificar sua performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC = 0.7969738651994498\n",
      "AP = 0.6299727951771387\n"
     ]
    }
   ],
   "source": [
    "#Média Simples\n",
    "p_ensemble_média_simples = (p_lgm + p_lr + p_rf) / 3\n",
    "\n",
    "#Apurando os resultados\n",
    "print(\"ROC_AUC = {}\".format(roc_auc_score(y_val, p_ensemble_média_simples)))\n",
    "print(\"AP = {}\".format(average_precision_score(y_val, p_ensemble_média_simples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O próximo passo é avaliarmos a correlação entre as previsões com o intuito de buscar um ensemble que tenham modelos que não estejam correlacionados para maximizar a capacidade do ensemble de \"olhar pontos de vistas diferentes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>RF</th>\n",
       "      <th>LGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.749385</td>\n",
       "      <td>0.746689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.749385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM</th>\n",
       "      <td>0.746689</td>\n",
       "      <td>0.907141</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            LR        RF      LGBM\n",
       "LR    1.000000  0.749385  0.746689\n",
       "RF    0.749385  1.000000  0.907141\n",
       "LGBM  0.746689  0.907141  1.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando a correlação\n",
    "pd.DataFrame({\"LR\": p_lr, \"RF\": p_rf, \"LGBM\": p_lgm}).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso, é complicado, os modelos estão muitos correlacionados. Vamos criar uma média ponderada com base na Regressão Logística e LGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC = 0.8005657782045625\n",
      "AP = 0.6339771056912653\n"
     ]
    }
   ],
   "source": [
    "#Média ponderada\n",
    "p_ensemble_média_ponderada = 0.6*p_lr + 0.4*p_lgm\n",
    "\n",
    "#Apurando os resultados\n",
    "print(\"ROC_AUC = {}\".format(roc_auc_score(y_val, p_ensemble_média_ponderada)))\n",
    "print(\"AP = {}\".format(average_precision_score(y_val, p_ensemble_média_ponderada)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anotações em relação as simulações:\n",
    "* Ap = 0.6402783961532013 e ROC_AUC = 0.8043756974903326 - 0.5 LR / 0.5 LGBM\n",
    "* Ap = 0.6454420943817779 e ROC_AUC = 0.8065298071682542 - 0.4 LR / 0.6 LGBM\n",
    "* Ap = 0.6464997305656753 e ROC_AUC = 0.8061924164958085 - 0.3 LR / 0.7 LGBM\n",
    "* Ap = 0.6457905886080421 e ROC_AUC = 0.8046767537826686 - 0.2 LR / 0.8 LGBM\n",
    "\n",
    "Vamos utilizar o seguinte ensemble:\n",
    "* Ap = 0.6464997305656753 e ROC_AUC = 0.8061924164958085 - 0.3 LR / 0.7 LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportando os Modelos\n",
    "\n",
    "Nesta etapa, vamos exportar os modelos. É recomemdado fazer a exportação pelo joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title_vectorizer.pkl.z']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib as jb\n",
    "\n",
    "jb.dump(mdl_lgm, \"lgbm.pkl.z\")\n",
    "jb.dump(lr_pipeline, \"logistic_reg.pkl.z\")\n",
    "jb.dump(title_vec, \"title_vectorizer.pkl.z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para carregar o modelo basta utilizar a linha de comando jb.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informações Importantes\n",
    "\n",
    "* Não foi utilizado para este projeto dados de teste, apenas validação e treino. Portanto, a forma que foi utilizada pode ter overfitado um pouco os resultados, mas sem gerar problemas drásticos na predição. Isso é possível avaliar pelos scores, o resultado não deu algo muito próximo dos valores máximos, que é um grande indicativo de overfitting. Além disso, o Mario comentou que antigamente ele dividia entre treino, validação e teste, porém, com a experiência ele avaliou que não existe teste melhor do que colocar o modelo em produção para avaliar os resultados obtidos (Teste em Produção). \n",
    "* Comentário do Mario Filho sobre não retreinar com todos os dados: \"Eu fazia muito isso de retreinar usando todos os dados, até encontrar um caso em que o modelo ficou bem diferente (os dados eram muito ruidosos). Em geral não acho que valha a pena retreinar fora de competições. Você acaba perdendo a sua estimativa da distribuição de probabilidades que ele prevê (e muda o ponto de corte, se tiver um). Uma alternativa a isso é fazer uma CV, tunar e salvar um modelo por fold e usar a média deles como previsão. Ainda assim acho que, na prática, a diferença no score não compensa.\"\n",
    "* Segundo comentário do Mario Filho sobre levar para produção um modelo com pouca performance: \"Boa noite, Matheus. A decisão de colocar em produção leva em conta duas coisas: se bate a solução atual e se o esforço de engenharia compensa. 20% pode ser muito ou pode ser pouco. Um AUC de 0.52 para um fundo de investimentos é muito bom. Para um sistema de recomendação em e-commerce, não é. As métricas de ML (como AP) servem só para ter uma ideia se a solução é melhor que uma baseline (normalmente a solução atual que a empresa usa), por isso eu recomendo iterar rápido e colocar em produção para ver o valor real. Tudo depende de quanto a empresa vai ganhar a mais ou gastar a menos por usar a solução. Já vi casos em que a melhora nas métricas de ML foi pequena, testes em produção mostraram que a solução nova era ligeiramente melhor e a empresa estava super feliz com os resultados de negócios. Resumindo, as métricas de ML são mais úteis como um \"primeiro filtro\" para tirar soluções muito ruins. Elas ajudam a gente a ter uma noção do que deve funcionar na prática (em métricas de negócios que são difíceis de medir offline), mas é comum ouvir casos em que métricas de ML estavam boas e o modelo em produção ficou ruim e vice-versa. Resumindo 2 (eu vou lembrando e comentando hehehe): pense sempre nessas métricas (qualquer métrica offline) como correlacionadas com as métricas em produção, mas não como indicadores perfeitos. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
